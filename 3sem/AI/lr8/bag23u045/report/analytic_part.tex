\chapter{Аналитическая часть}

Метод главных компонент (Principal Component Analysis, PCA) — это техника уменьшения размерности,
которая используется для преобразования набора коррелированных переменных в меньший набор некоррелированных переменных,
называемых главными компонентами. Метод подразумевает сохранение как можно большей полезной информации об исходных данных при уменьшении их количества.

\section{Метод главных компонент}\label{PCA}

Основные шаги PCA:
\begin{enumerate}
    \item центрирование данных. В каждом измерении (признаке) вычисляется среднее значение, 
    которое затем вычитается из значений этого признака для всех наблюдений, чтобы данные были центрированы вокруг нуля.
    \item вычисление ковариационной матрицы. Определяется ковариационная матрица данных, которая показывает, как различаются признаки относительно друг друга.
    \item получение собственных векторов и собственных значений. Вычисляются собственные векторы и собственные значения ковариационной матрицы. 
    Собственные векторы указывают направление главных компонент, а собственные значения показывают, сколько дисперсии данных захвачено в каждом направлении.
    \item выбор главных компонент. Главные компоненты выбираются на основе величины их собственных значений. 
    Обычно выбирают те компоненты, которые объясняют наибольшую долю дисперсии данных.
    \item преобразование данных. Данные проектируются на пространство, определенное выбранными главными компонентами, что приводит к уменьшению размерности.
\end{enumerate}

Перед применением PCA необходимо иметь вектора документов в формате {слово : кол-во повторений в тексте}. Из этого вектора мы извлекаем только кол-во повторений да так,
чтобы все вектора получились упорядоченные и одной размерности. 
Главные компоненты — это новые переменные (основные оси), которые вычисляются так, чтобы максимально описывать разброс данных.
После применения PCA часть информации может быть потеряна, поэтому результаты мер близости могут немного отличаться от тех, которые могли бы быть получены,
если бы работали с исходными данными.

\section{Способ сравнения до PCA и после}

Сравнение того, как повлиял PCA на степень близости документов, производится с помощью косинусной меры близости. 
В качестве входных данных для неё будут подваваться матрицы близости документов (до и после PCA). Результаты будут градироваться следующим образом:
\begin{itemize}
    \item близко к 1. Означает, что векторы полностью совпадают или находятся в одном направлении (максимальная схожесть). 
    \item близко к 0. Означает, что векторы ортогональны, т.е. они не имеют ничего общего (нет схожести).
    \item близко к -1. Означает, что векторы направлены в противоположные стороны (полная противоположность).
\end{itemize} 

Косинусная мера независима от масштаба векторов, что делает её удобной для сравнения структуры матриц, поскольку она учитывает только направление векторов, игнорируя их длину. 

\section*{Вывод}

В разделе был рассмотрен метод главных компонент (PCA) как способ уменьшения размерности данных. 
Описаны основные этапы применения PCA, начиная с центрирования данных и заканчивая проекцией на новое пространство главных компонент. 
Также проведен анализ того, как применение PCA влияет на степень близости между документами, с использованием косинусной меры, 
которая была выбрана для сравнения близости документов до и после уменьшения размерности.

\clearpage

