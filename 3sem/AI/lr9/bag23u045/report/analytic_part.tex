\chapter{Аналитическая часть}

Кластеризация является одной из ключевых задач анализа данных и машинного обучения. 
Её цель — разделение множества объектов на группы (кластеры) таким образом, 
чтобы объекты внутри одного кластера были более схожи между собой, чем с объектами из других кластеров. 

\section{Методы кластеризации}

\subsection{Метод \textit{k-means}}
\textit{k-means} — один из наиболее популярных алгоритмов кластеризации. 
Его цель заключается в минимизации суммы квадратов отклонений объектов от центров их кластеров. 
Формально:

\begin{math}
J = \sum_{i=1}^k \sum_{x \in C_i} \|x - \mu_i\|^2
\end{math}\cite{lib:kmeans},
где $k$ — количество кластеров, $C_i$ — множество объектов в кластере $i$, $\mu_i$ — центр кластера $i$ (среднее значение объектов кластера).

Процесс выполнения:
\begin{enumerate}
    \item инициализация $k$ центров кластеров случайным образом.
    \item назначение каждого объекта ближайшему центру.
    \item пересчёт центров кластеров
    \item повторение шагов 2-3 до сходимости.
\end{enumerate}

\subsection{Метод \textit{c-means} (размытая кластеризация)}
Метод \textit{c-means} является обобщением \textit{k-means} и основывается на размытом распределении принадлежности объектов к кластерам. 
Объекты могут принадлежать нескольким кластерам с различными степенями принадлежности. 
Функция оптимизации:

\begin{math}
J = \sum_{i=1}^k \sum_{j=1}^n u_{ij}^m \|x_j - \mu_i\|^2,
\end{math}\cite{lib:cmeans}, где $u_{ij}$ — степень принадлежности объекта $x_j$ к кластеру $i$, $m > 1$ — параметр размытости.

Алгоритм:

\begin{enumerate}
    \item инициализация матрицы принадлежностей.
    \item обновление центров кластеров:
        \begin{math}
        \mu_i = \frac{\sum_{j=1}^n u_{ij}^m x_j}{\sum_{j=1}^n u_{ij}^m}.
        \end{math}\cite{lib:cmeans}
    \item обновление матрицы принадлежностей:
        \begin{math}
        u_{ij} = \frac{1}{\sum_{k=1}^k \left(\frac{\|x_j - \mu_i\|}{\|x_j - \mu_k\|}\right)^{\frac{2}{m-1}}}.
        \end{math}\cite{lib:cmeans}
    \item повторение шагов 2-3 до сходимости.
\end{enumerate}

\subsection{Иерархическая кластеризация}
Иерархическая кластеризация строит древовидную структуру кластеров (дендрограмму). 
Алгоритм работает по одному из двух подходов:

\begin{itemize}
    \item \textbf{агломеративный подход}. Начинается с каждого объекта в отдельном кластере, затем кластеры объединяются.
    \item \textbf{дивизионный подход}. Начинается с одного кластера, включающего все объекты, затем кластеры делятся.
\end{itemize}

Критерий объединения или разделения кластеров может быть основан на различных метриках, 
таких как минимальное расстояние (метод одиночной связи) или максимальное расстояние (метод полной связи).

\section{Выбор количества класетров}
Кластеризация является важным методом анализа данных, используемым для разделения объектов на группы (кластеры) с учетом их схожести. 
Однако выбор оптимального количества кластеров $k$ представляет собой сложную задачу. 
В данной работе рассмотрены два подхода к определению оптимального числа кластеров: метод локтя для k-means и c-means, 
а также использование дендрограмм в иерархической кластеризации.

\subsection{Метод локтя}
Метод локтя является визуальным подходом к выбору оптимального количества кластеров в алгоритмах k-means и c-means. 

Метод основан на анализе изменения значения функции стоимости $W(k)$ при увеличении числа кластеров $k$. 
Для k-means и c-means функция стоимости представляет собой сумму квадратов расстояний от объектов до ближайшего центроида (в k-means) 
или до центроидов с учетом весов принадлежности (в c-means).

\subsection{Иерархическая кластеризация и дендрограммы}
Иерархическая кластеризация позволяет построить дерево кластеров (дендрограмму), 
где каждый узел представляет собой объединение кластеров. 
Определение оптимального числа кластеров осуществляется на основе анализа структуры дендрограммы.
осуществляется поиск самой длинной вертикальной непрерывной линии в дендрограмме.
По ней проводится горизонтальная линия, которая определяет оптимальное количество кластеров, исходя из количества пересечений вертикальных линий.


\section{Заключение}
Выбор метода кластеризации зависит от особенностей данных и целей анализа. 
Для компактных и чётко разделённых данных хорошо подходит \textit{k-means}. 
Для данных с размытыми границами кластеров рекомендуется использовать \textit{c-means}. 
Иерархическая кластеризация подходит для анализа структуры данных и визуализации.

\clearpage

% \begin{math}
%     \label{mean}
%     Mean = \frac{1}{N}\sum_{j}^{N}x_{ij}
% \end{math} \cite{lib:mean}