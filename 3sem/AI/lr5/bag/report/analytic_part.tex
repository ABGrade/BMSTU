\chapter{Аналитическая часть}

Нейронные сети (\textit{Artificial Neural Networks, ANN}) представляют собой одну из ключевых технологий в области машинного обучения, 
которая имитирует принципы работы биологических нейронов. 
Эти модели состоят из набора взаимосвязанных узлов (\textit{нейронов}), организованных в слои. 
Нейроны в слоях применяют к данным последовательность линейных и нелинейных преобразований, 
что позволяет выявлять сложные зависимости в данных и решать задачи, такие как классификация, регрессия и прогнозирование.

Процесс обучения нейронной сети включает несколько этапов. 
Одним из важнейших понятий здесь является эпоха (\textit{epoch}), 
которая соответствует одному полному прохождению всех тренировочных данных через модель. 
На каждой эпохе веса модели обновляются с целью минимизации ошибки между предсказанными и истинными значениями. 
Слишком малое количество эпох может привести к недообучению (\textit{underfitting}), а слишком большое — к переобучению (\textit{overfitting}).

\section{Классификация данных и архитектура нейронной сети}

Для решения задачи классификации, нейронная сеть обрабатывает входные данные через последовательность слоёв. 
Каждый слой играет свою роль:
\begin{itemize}
    \item входной слой преобразует данные в формат, пригодный для дальнейших вычислений. 
    Например, для изображений это может быть нормализация пикселей и их представление в виде плоского вектора.
    \item скрытые слои (\textit{hidden layers}) выполняют извлечение признаков, 
    которые помогают выявить сложные закономерности в данных.
    \item выходной слой (\textit{output layer}) определяет вероятности принадлежности объекта к каждому из классов 
    с использованием функции активации, например, \textit{softmax}.
\end{itemize}

Для оценки качества классификации используется метрика точности (\textit{accuracy}), 
определяемая как доля правильных предсказаний от общего числа примеров:

\begin{math}
    Accuracy = \frac{\text{Количество правильных предсказаний}}{\text{Общее количество примеров}}
\end{math} \cite{lib:neuron}

Эта метрика показывает, насколько хорошо модель справляется с задачей классификации.

\section{MNIST dataset}

MNIST (\textit{Modified National Institute of Standards and Technology}) — это один из наиболее известных и
часто используемых наборов данных для задач классификации изображений. 
Датасет включает в себя:
\begin{itemize}
    \item 60,000 тренировочных изображений и 10,000 тестовых изображений.
    \item изображения размером \(28 \times 28\), представляющие рукописные цифры от 0 до 9.
\end{itemize}

Каждое изображение ассоциируется с меткой класса, что делает MNIST подходящим для обучения моделей и проверки их качества. 
Его простота и стандартизированность позволяют использовать датасет для тестирования различных подходов к классификации.

\section{Функция активации и функция потерь}

Одним из важнейших компонентов нейронной сети является функция активации, определяющая, 
как нейроны реагируют на входные данные. 
В данном исследовании была использована функция активации ReLU (\textit{Rectified Linear Unit}), 
которая задаётся формулой:

\begin{math}
    f(x) = \max(0, x)
    \label{ReLU}
\end{math} \cite{lib:ReLU}

ReLU популярна благодаря своей способности справляться с эффектом затухающих градиентов (\textit{vanishing gradients}), 
что делает обучение глубоких моделей более эффективным. 
Однако у неё есть недостаток: некоторые нейроны могут стать "мёртвыми", то есть их выход всегда будет равен нулю.

Для задачи классификации вероятностных распределений была применена функция потерь KL Divergence (\textit{Kullback-Leibler Divergence}). 
Она измеряет, насколько одно вероятностное распределение \(P\) (истинные метки) отличается от другого распределения \(Q\) (предсказания модели):

\begin{math}
    D_{KL}(P || Q) = \sum_{i} P(i) \log \frac{P(i)}{Q(i)}
    \label{KLDivergence}
\end{math} \cite{lib:KLD}

Эта мера помогает оценивать, насколько точно модель предсказывает вероятности классов, 
что особенно полезно при использовании функции \textit{softmax} в выходном слое.

\section*{Вывод}

Нейронные сети являются мощным инструментом для решения задач классификации, таких как распознавание цифр. 
Использование функции активации ReLU способствует эффективному обучению модели, 
а KL Divergence позволяет точно оценивать её предсказания. 

\clearpage

