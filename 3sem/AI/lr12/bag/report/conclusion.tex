\ssr{ЗАКЛЮЧЕНИЕ}

В рамках данной лабораторной работы была успешно решена задача разработки алгоритма управления роботизированной кистью Adroit 
для выполнения задачи Adroit Hammer с использованием методов обучения с подкреплением. 

В начале работы были поставлены и выполнены следующие задачи: во-первых, был выбран и реализован алгоритм обучения 
с подкреплением Proximal Policy Optimization (PPO), как наиболее подходящий по критериям стабильности, 
универсальности и простоты реализации для данной задачи. 
Во-вторых, проведено обучение агента, который взаимодействовал со средой симуляции AdroitHandHammer-v1, 
представляющей собой виртуальную модель роботизированной кисти Adroit Hand. 
Процесс обучения включал в себя получение наблюдений о состоянии среды, выполнение действий, 
направленных на управление рукой-роботом, и получение вознаграждений, зависящих от успешности выполнения задачи. 
В-третьих, были проанализированы результаты обучения и оценено качество выполнения задачи на основе графика суммарной 
награды и визуализации действий агента в среде. Анализ алгоритмов обучения с подкреплением показал, 
что PPO является оптимальным выбором для решения поставленной задачи. 
Разработана и реализована модель обучения агента, включающая этапы инициализации, тренировки, тестирования и визуализации. 
В ходе обучения агент успешно освоил стратегию управления роботизированной кистью для выполнения задачи забивания гвоздя в среде AdroitHandHammer-v1. 
График обучения демонстрирует стабильный рост суммарной награды, что свидетельствует об эффективности выбранного алгоритма и успешном освоении агентом требуемых навыков. 
Визуализация действий агента подтверждает, что он научился манипулировать молотком и достигать заданной целевой позиции гвоздя. 

Таким образом, цель лабораторной работы достигнута – разработан алгоритм управления роботизированной кистью Adroit, 
позволяющий успешно решать задачу Adroit Hammer с использованием методов обучения с подкреплением. 
