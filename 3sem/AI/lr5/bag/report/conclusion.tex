\ssr{ЗАКЛЮЧЕНИЕ}

В рамках данного исследования была выполнена классификация данных из MNIST датасета с использованием нейросетевого подхода, 
функции активации ReLU и функции потерь KL Divergence. 
Исследование было направлено на достижение поставленной цели — классификации данных

Для оценки состояния переобучения и недообучения проведён анализ точности на обучающих и тестовых выборках при различных пропорциях их разбиения. 
В рамках исследования были использованы следующие соотношения: от 10:90 до 90:10. 
Наблюдалось, что увеличение размера обучающей выборки приводит к увеличению точности модели на обучающих данных. 
При этом важно соблюдать баланс между обучающей и тестовой выборками, чтобы не приводить модель к недообучению или переобучению.

Увеличение количества скрытых слоев увеличивает точность модели на обучающих данных. 
Но здесь, также важно соблюдать баланс между количеством скрытых слоев, потому что она может вести к ненужному увеличению сложности модели.